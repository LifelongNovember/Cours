> Généré depuis [StackEdit](https://stackedit.io/). Si ce fichier est sur GitHub, vous êtes en train de lire un backup du document original, qui est accessible [ici](https://frama.link/aden-iutsd) (avec de belles formules à la place des entrées Latex).
>
> Une authentification est demandée. 
> > Compte lecture seule :
> > Identifiant : **reader**
> > Mot de passe : **reader**

# Cours

## Statistique inférentielle

### Estimation

Estimation : Variable $X_0$ associée à une population $\Omega$. On souhaite estimer un paramètre $\theta$ de la loi de $X_0$ à partir d'un échantillon (sous-ensemble de $\Omega$).

⇒ L'estimation peut se faire par un nombre (estimation ponctuelle) ou un intervalle (intervalle de confiance).

Modélisation : $X_0 : \Omega \to \R$, $X_0(\omega) = x$, $\omega$ choisi au hasard dans $\Omega$, on s'intéresse à la réalisation $x$ de $X_0$. One ne connaît pas la loi de $X_0$, mais on veut en déterminer un paramètre $\theta$ (par exemple, la variance, l'écart-type...).

#### Caractère qualitatif : 
$$X_0 \sim \mathcal B (1, \pi)$$ $$\begin{aligned} 
P(X_0 = 1)  =\pi &, P(X_0 = 0) = 1 - \pi \\
E(X_0) = \pi &, V(X_0) = \pi(1 - \pi)
\end{aligned}$$

> $\Omega$ : Ensemble des pièces produites par une machine. Pour une pièce $\omega$ :
> * $X_0( \omega) = 1$ si la pièce est défectueuse,
> * $X_0(\omega) = 0$ si la pièce n'est pas défectueuse.
> 
> $\pi$ est la proportion de pièces défectueuses.

#### Caractère quantitatif :  
$X_0 \sim \mathcal L_0$, $\mathcal L_0$ n'est pas connue.
$$E(X_0) = \mu, V(X_0) = \sigma^2$$

> $\Omega$ : Ensemble des étudiants de l'IUT.
> * $X_0(\omega)$ : taille d'un étudiant $\omega$
> * $\mu$ : taille moyenne

#### Loi observée 
$n$ expériences aléatoires indépendantes $\mathcal E_i (1 \leqslant i \leqslant n)$. $X_i$ associée à $\mathcal E_i$, qui a la même loi que $X_0$. $(X_1, \dots, X_n)$ indépendantes suivant cette loi est l'**échantillon** de cette loi.

$E(X_i) = E(X_0) = \pi$ et $V(X_i) = V(X_0) = \pi (1 - \pi)$ (qualitatif),
$E(X_i) = E(X_0) = \mu$, $V(X_i) = V(X_0) = \sigma^2$ (quantitatif)

À un échantillon $(\omega_1, \dots, \omega_n) \in \Omega^n$ est associée la réalisation $(X_1(\omega_1), \dots, X_n(\omega_n)) = (x_1, \dots , x_n)$ du vecteur aléatoire $X = (X_1, \dots, X_n) : \Omega^n \to \R^n$.

En notant $\Omega_n = \{\omega_1, \dots, \omega_n \}$, $Y(\omega_i) = X_i(\omega_i)$ et $Y(\Omega_n) = \{Y(\omega_i), 1 \leqslant i \leqslant n\} = \{y_1, \dots, y_n\} \ (m \leqslant n)$, la loi de $Y$ est
$$ P(Y = y_j) = {\lvert \omega_i, X_i(\omega_i) = y_j \rvert \over n} \text{ (loi observée)} $$

⇒ $E(Y) = f_n$, $V(Y) = f_n (1 - f_n)$ (qualitatif)
⇒ $\displaystyle E(Y) = \overline x = {1 \over n} \sum_{i = 1}^n x_i$, $\displaystyle V(Y) = \sigma^2 _n = {1 \over n} \sum_{i = 1}^n (x_i - \overline x)^2$ (quantitatif)

**Estimateur** $T_n = \phi(X_1, ... , X_n)$ : fonction des variables aléatoires de l'expérience dont la valeur $t$ est prise comme estimation du paramètre $\theta$.
Pour que $T_n$ soit intéressant, il est nécessaire que la probabilité que $T_n$ prenne une valeur proche de $\theta$ soit grande.

**Biais** : $E(T_n) - \theta$. 
$T_n$ est **sans biais** si $E(T_n) = \theta$.
$T_n$ est **asymptotiquement sans biais** si $\displaystyle \lim_{n \to +\infin} E(T_n) = \theta$.

⇒ Un bon estimateur est un estimateur sans biais et de variance faible.
(CF cas quantitatif et qualitatif)

Estimation de la variance : 
(quantitatif) : on pose $\displaystyle T_n = {1 \over n} \sum_{i = 1}^n (X_i - \overline X) ^2 = {1\over n} \sum_{i = 1}^n X_i^2 - \overline X^2$. $\displaystyle E(T_n) = E \left ( {1 \over n} \sum_{i = 1}^n X_i^2  - \overline X^2 \right ) = {1 \over n} \sum_{i = 1}^n E(X_i^2) - E(\overline X^2)$ (... CF 18) $\displaystyle E(T_n) = {{n - 1} \over n} \sigma^2 \neq \sigma^2$ mais $\displaystyle E(T_n) = \underset{n \to + \infin}{{{n - 1} \over n} \sigma^2 \to \sigma^2}$

⇒ $T_n$ n'est pas sans biais mais asymptotiquement sans biais : $\displaystyle T'_n = {n \over {n - 1}} T_n = {1 \over {n - 1}} \sum_{i = 1}^n (X_i - \overline X)^2$ (CF 19)

Récapitulatif : CF 21

$\overline X$ : moyenne empirique, $S^2$ : variance empirique ou non-biaisée.

Quand l'espérance $\mu$ est connue, on peut utiliser l'estimateur de la variance $\displaystyle S^2 = {1 \over n} \sum_{i = 1}^n (X_i - \mu)^2$
⇒ $E(S^2) = \sigma^2$ (estimateur sans biais)
⇒ $\underset{n \to +\infin}{V(S^2) \to 0}$ (bon estimateur) (CF 22)

**Vraisemblance** de l'échantillon $(X_1, \dots, X_n)$ : $\mathcal V(x_1, \dots, x_n, \theta) = P_\theta ((X_1 = x_1) \cap \dots \cap (X_n = x_n)) = P_\theta(X_1 = x_1) \times \dots \times P_\theta(X_n = x_n)$ (indépendance des $X_i$)

**Maximum de vraisemblance** : $T^m$, estimateur qui rend l'échantillon obtenu le plus probable.

**Méthode des moments** : Pour construire un estimateur de $\theta$, on peut utiliser des **moments** $E(X^k)$ et $E \left ( (X - E(X))^k \right ) : E(X) = \overline X, E(X^2) = \dots$ 
CF 25

### Intervalle de confiance

⇒ On s'intéresse à l'erreur $\lvert t - \theta \rvert$ commise entre la valeur estimée $t$ et $\theta$.

Un **intervalle de confiance** pour $\theta$ de **seuil de confiance** (ou niveau de confiance) $1 - \alpha$ est un intervalle $[T_1, T_2]$ avec $T_1 = f_1 (X_1, \dots, X_n)$ et $T_2 = f_2 (X_1, \dots, X_n)$ vérifiant $P(T_1 \leqslant \theta \leqslant T_2) \geqslant 1 - \alpha$.

⇒ On appellera également intervalle de confiance pour $\theta$ de seuil de confiance $1 - \alpha$ toute **réalisation** $[t_1, t_2]$ d'un intervalle de confiance $[T_1, T_2]$.

#### Intervalle de confiance pour une moyenne ($\sigma$ connu) 
$X_1, \dots, X_n$ indépendantes suivant $\mathcal N(\mu, \sigma)$. Alors, $S_n = X_1 + \dots + X_n \sim \mathcal N(n \mu, \sqrt n \sigma)$ et $\overline X = {S_n \over n} \sim \mathcal N (\mu, \sigma / \sqrt n)$.
On en déduit ${{\overline X - \mu} \over {\sigma / \sqrt n}} \sim \mathcal N (0,1)$.
Soit $\alpha > 0$. $\exists \ a > 0$ : $P \left ( \left \lvert {{\overline X - \mu} \over {\sigma / \sqrt n}} \right \rvert \leqslant a \right ) = 1 - \alpha$.  (CF 27)
(CF BN1)

Sur un grand nombre d'intervalle de niveau de confiance $1 - \alpha$, $1 - \alpha$ d'entre-eux contiennent $\theta$ et $\alpha$ ne le contiennent pas.

#### Intervalle de confiance pour une moyenne ($\sigma$ inconnu) 
$X_1, \dots , X_n$ indépendantes suivant $\mathcal N(\mu, \sigma)$. On utilise $\displaystyle S^2 = \sum_{i = 1}^n {{(X_1 - \overline X)^2} \over {n - 1}}$ :  CF 31
$\alpha > 0$ : $\exists \ t_{n - 1;1 - \alpha /2} > 0$ , CF 32

#### Intervalle de confiance pour une variance ($\mu$ connu)
$X_1, \dots, X_n$ indépendantes suivant $\mathcal N(\mu, \sigma)$. On utilise $\displaystyle S^2 = \sum_{i = 1}^n {{(X_i - \mu)}^2 \over n}$ : CF 34
CF BN2

#### Intervalle de confiance pour une variance ($\mu$ inconnu)
$X_1, \dots, X_n$ indépendantes suivant $\mathcal N(\mu, \sigma)$. On utilise $\displaystyle S^2 = \sum_{i = 1}^n {{(X_i - \overline X)}^2 \over {n - 1}}$ : CF 37/38

#### Intervalle de confiance pour une proportion

$X_i \sim \mathcal B(1 , \pi) \ (1 \leqslant i \leqslant n)$. $S_n = X_1 +  \dots + X_n \sim \mathcal B(n, \pi)$. On suppose $n$ assez grand pour que $\mathcal B(n, \pi) \approx \mathcal N \left ( n \pi, \sqrt {n \pi (1 - \pi)} \right )$ et $\overline X = {S_n \over n} \sim \mathcal N \left ( \pi, \sqrt {\pi (1 - \pi) /n} \right )$. Soit $\alpha > 0$, CF 40/41

Autres méthodes : CF 44/46
##### Méthode de Clopper-Pearson
On pose $X \sim \mathcal  B(n, \pi)$, $0 \leqslant i \leqslant n$, $\overline x = {i \over n}$. On cherche un intervalle de confiance de $\pi$ de niveau $1 - \alpha$, ensemble $[p_1,p_2]$ des nombres $\pi$ vérifiant :
 * $P(X \leqslant i) \geqslant \alpha / 2 \ (\pi \leqslant p_2)$
 * $P(X \geqslant i) \geqslant \alpha / 2 \ (\pi \geqslant p_1)$

# TD

> ## Intégration

## Exercice 1 - Sommes de Riemann

$$n \geqslant  1 : s_n = \sum_{i=0}^{n-1} {n \over {n^2 + i^2}}  \ ; \  s_n ' = \sum_{i = 1}^{n} {n \over {n^2 + i^2}} $$

> ### Préciser $s_1$, $s_2$, $s_3$, ainsi que $s'_1$, $s'_2$ et $s'_3$.

$$ \footnotesize \begin{array}{c|c} \begin{aligned}
&s_1 = \sum_{i = 0}^{0} {1 \over {1 + i^2}} = 1 \\
&s_2 = \sum_{i = 0}^1 {2 \over {2^2 + i^2}} = {2 \over 4} + {2 \over 5} \\
&s_3 = \sum_{i = 0}^2 {3 \over {3^2 + i^2}} = {3 \over 9} + {3 \over 10} + {3 \over 13} 
\end{aligned} & ~ \begin{aligned}
&s'_1 = \sum_{i = 1}^1 {1 \over {1 + i^2}} \\
&s'_2 = \sum_{i = 1} ^2 {2 \over {2 + i^2}} = {2 \over 5} + {2 \over 8} \\
&s'_3 = \sum_{i = 1}^3 {3 \over {3^2 + i^2}} = {3 \over 10} + {3 \over 13} + {3 \over 18}
\end{aligned} \end{array}$$

> ### Montrer que pour tout entier $n \geqslant 1$, $$\footnotesize{s_n = {1 \over n}\sum_{i = 0}^{n -1} {1 \over {1 + \left ( i \over n \right )^2}}} \text{ et } \footnotesize{s'_n = {1 \over n} \sum_{i = 1}^n {1 \over {1 + \left ( i \over n \right )^2}}}$$ On note $f$ la fonction définie sur $[0,1]$ par $\footnotesize {f(x) = {1 \over {1 + x^2}}.}$ Montrer que : $$\footnotesize{s_n = {1 \over n} \sum_{i = 0}^{n - 1} f \left ( i \over n \right ) \text{ et } s'_n = {1 \over n} \sum_{i = 1}^n f \left ( i \over n \right )}$$

$$ \begin{aligned}
s_n &= \sum_{i = 0}^{n - 1}  {n \over {n^2 + i^2}} = \sum_{i = 0}^{n - 1} {{n^2 \left ( 1 \over n \right )} \over {{n^2 \left ( 1 +  \left ( i \over n \right )^2 \right )}}} = \sum_{i = 0}^{n - 1} {{1 \over n} \over {1 + \left ( i \over n \right )^2}} \\ &= {1 \over n} \sum_{i = 0}^{n - 1} {1 \over {1 + \left ( i \over n \right )^2}} = {1 \over n} \sum_{i = 0}^{n - 1} f \left ( i \over n \right ) \\ &\text{ avec } f(x) = {1 \over {1 + x^2}} \text{ sur } [0,1]. 
\end{aligned}$$
De même,
$$ \begin{aligned}s'_n &= {1 \over n} \sum_{i = 1}^n {1 \over {1 + \left ( i \over n \right )^2}} =  {1 \over n} \sum_{i = 1}^n f \left ( i \over n \right ) = {1 \over n} \sum_{i = 1}^n f \left ( i \over n \right ) \\ &\text{avec }f(x) = {1 \over {1 + x^2}} \text{ sur } [0,1].
\end{aligned}$$

> ### En déduire : $$\footnotesize{\lim_{n \to +\infin} s_n = \lim_{n \to +\infin} s'_n = \int_0^1 {1 \over {1 + x^2}} \ dx}$$  Préciser $\displaystyle \scriptsize { \int_0^1 {1 \over {1 + x^2} } \ dx}$.

$$\begin{aligned}
&s_n = {1 \over n} \left ( f(0) + f \left ( 1 \over n \right ) + \dots + f \left ( {n - 1}  \over n \right ) \right ) \text{ sur } [0,1]. \\
&s'_n = {1 \over n} \left ( f \left ( 1 \over n \right ) + \dots + f \left ( {n - 1} \over n \right ) + f(1) \right ) \text{ sur } [0,1].
\end{aligned}$$

$$\begin{aligned}
\lim_{n \to +\infin} s_n = \lim_{n \to + \infin} s'_n &= \int_0^1 f(x) \ dx = \int_0^1 {1 \over {1 + x^2}} \ dx \\ &= \arctan(1) - \arctan(0) = { \pi \over 4}
\end{aligned}$$

> ### Interpréter graphiquement.
$$ f(x) = {1 \over {1 + x^2}} \ ; \ f'(x) = {{-2x} \over {(1 + x)^2}} $$

$$
\begin{array}{|c|ccr|}
\hline
x     & 0  &     & 1  \\
\hline
f'(x) & 0  &  - & - 1/2 \\
\hline
 & 1  & & \\       % ligne des valeurs "max"
f(x) &  &\searrow   & \\   % flèches
& & & 1/2 \\          % ligne des valeurs "min"
\hline
\end{array}
$$

![](https://i.imgur.com/FQ7pbW7.png)

> ### Donner un encadrement de $\pi$ en remarquant que : $$\footnotesize \forall \ n \geqslant 1, s'_n \leqslant \int_0^1 {1 \over {1 + x^2}}dx \leqslant s_n$$

$$s'_n \leqslant {\pi \over 4} \leqslant 4 s_n \implies 4 s'_n \leqslant \pi \leqslant 4 s_n $$

## Exercice 2 - Calcul d'intégrales

> ### $\displaystyle \int_0^1 (x^2 -x + 1) \ dx$

$$
\begin{aligned}
\int_0^1(x^2 - x + 1) \ dx &= \int_0^1 x^2 \ dx - \int_0^1  x \ dx + \int_0^1 1 \ dx \\
&= \left [ x^3 \over 3 \right ]^1_0 - \left [ x^2 \over 2 \right ]_0^1 + [ x ]_0 ^1 \\
&= \left ( {1 \over 3} - 0 \right ) - \left ( {1 \over 2} - 0 \right ) + (1 - 0) \\
&= {1 \over 3} - {1 \over 2} + 1 = {5 \over 6}
\end{aligned} $$

> ### $\displaystyle \int_0^{\pi/2} \cos x \ dx$

$$ \int_0^{\pi / 2} \cos x \ dx = [ \sin x ]_0^{\pi / 2} = 1 $$

> ### $\displaystyle \int_0^4 e^{2x} \ dx$

$$ \int_0^4 e^{2x} \ dx = \left [ e^{2x} \over 2 \right ]_0^4 = {e^8 \over 2} - {1 \over 2} $$

> ### $\displaystyle \int_0^1 2x e^{x^2} \ dx$

$$ \int_0^1 2x e^{x^2} \ dx = \left [ e^{x^2} \right ]_0^1 = e - 1 $$

> ### $\displaystyle \int_0^{\pi / 2} \tan x \ dx$

$$\footnotesize \int_0^{\pi / 2} \tan x \ dx = \int_0^{\pi / 4} {{\sin x} \over {\cos x}} \ dx = [ - \ln(\cos x)]_0 ^{\pi / 4} = - \ln \left ( {\sqrt 2} \over 2 \right )$$

## Exercice 3 - Intégration par parties et intégrale généralisée

> ### $x$ est un réel quelconque. En intégrant par parties, préciser $\scriptsize \displaystyle \int_0^x t e^{-t} \ dt$.

$$
\begin{aligned}
\int_0^x t e^{-t} \ dt &= \left [ t \left ( - e^{-t} \right ) \right ]_0^x - \int _0 ^x 1 \left ( - e^{-t} \right ) \ dt \\
&= -x e^{-x} - \int_0^x -e^{-t} \ dt \\
&= -x e^{-x} - \left [ e^{-t} \right ]_0^x \\
&= -xe^{-x} - (e^{-x} - 1) = x e^{-x} - e^{-x} + 1
\end{aligned}$$

> ### En déduire la nature de $\scriptsize\displaystyle \int_0^{+ \infin} x e^{-x} \ dx$.

$$
\lim_{x \to + \infin} \underbrace {- x e^{-x}}_{\underset \text{ (croiss. comparées)} 0} - \underbrace {e^{-x}}_0  + 1 = 1 \\ \implies \text{convergente et } \int_0^{+ \infin} x e^{-x} \ dx = 1
$$

> ### Interpréter graphiquement.

## Exercice 4 - Changement de variable et intégrale généralisée

> ### Changement de variable
>
>1. **Fonction**
>$$ {1 \over  {x^2 + 2x + 2}} = \dots  \text{ en fonction de } t$$
>2. **Différentielle**
>$$ dx = \dots = \dots \ dt $$
>3. **Bornes**
>$$\begin{aligned}
>x = -1 &\implies t = \dots \\
>x = y &\implies t = \dots
>\end{aligned}$$

---

> ### $y$ est un réel quelconque. Calculer $\scriptsize\displaystyle \int_{-1}^y {1 \over {x^2 + 2x + 2}} \ dx$ en utilisant le changement de variable $t = x + 1$.

1. Fonction
$$\footnotesize {1 \over {(t - 1)^2 + 2(t - 1) + 2}} = {1 \over {t^2 - 2t + 1 + 2t -2 + 2}} = {1 \over {t^2 + 1}}$$

2. Différentielle
$$dx = (t - 1)' \ dt = dt$$

3. Bornes
$$\begin{aligned} x = -1 &\implies t = -1 + 1 = 0 \\ x = y &\implies t = y + 1\end{aligned}$$

---

$$\begin{aligned}
\int_{-1}^y {1 \over {x^2 + 2x + 2}} \ dx &= \int_0^{y + 1} {1 \over {t^2 + 1}} \ dt \\ &=  [\arctan(t)]_0^{y + 1} = \arctan(y + 1) \underset {y \to +\infin}{\longrightarrow} {\pi \over 2}
\end{aligned}$$

> ### En déduire la nature de $\scriptsize \displaystyle \int_{-1}^{+\infin} {1 \over {x^2 + 2x + 2}} \ dx$.

$\displaystyle \int_{-1}^y {1 \over {x^2 + 2x + x}} \ dx$ est convergente :$$\displaystyle \int_{-1}^{+\infin} {1 \over {x^2 + 2x + x}} \ dx = {\pi \over 2}$$

> ### Interpréter graphiquement.

$$f(x) = {1 \over {x^2 + 2x + x}} \ ; \ f'(x) = - {{2x + 2} \over {(x^2 + 2x + x)^2}} \leqslant 0 $$ $$f(0) = {1 \over 2} \ ; \ \lim_{x \to +\infin} f(x) = 0$$

$$\begin{array}{|c|ccr|}
\hline
x     & -1  &     & + \infin  \\
\hline
f'(x) & 0  &  - & \\
\hline
 & 1/2  & & \\       % ligne des valeurs "max"
f(x) &  &\searrow   & \\   % flèches
& & & 0 \\          % ligne des valeurs "min"
\hline
\end{array}$$

> ## Variables aléatoires discrètes

## Exercice 5 - Variable aléatoire

> Préciser la loi de probabilité, la fonction de répartition, les représentations graphiques de celles-ci, l'espérance, la variance et l'écart-type de la variable aléatoire $X$ définie comme suit :
 > ### $X$ suit la loi uniforme sur $\{1, 2, 3\} : X \sim \mathcal U \left ( 1 \over 3 \right )$

$$ X(\Omega) = \{1, 2, 3\} $$

Loi de probabilité : $P(X = x_i), \ x_i \in X(\Omega)$

$$P(X = 1) = {1/3} \\ P(X = 2) = {1/3} \\ P(X = 3) = {1/3}$$ 

Fonction de répartition : $\displaystyle \underset{\mathscr D_F = \R}{F(x)} = P(X \leqslant x) = \sum_{x_i \leqslant x} P(X = x_i)$

$$ F(x) =\left \{ \begin{alignedat}{2}
 0 & &&: x \in \ \ ]\!-\!\infin, 1[  \\
0 + P(X = 1) &= 1/3 &&: x \in \ [1, 2[ \\
1/3 + P(X = 2) &= 2/3 &&: x \in \ [2, 3[ \\
2/3 + P(X = 3) &= 1 &&: x \in \ [3, +\infin[
\end{alignedat} \right. $$

![](https://i.imgur.com/ujWNNy0.png)$$\sixptsize [ \color{#D32F2F}{\text{Loi de probabilité}} \ \color{default} {;}  \ \color{#1565C0}{\text{Fonction de répartition}} \color{default} ]$$

$$
\footnotesize \begin{array}{rcccl}
E(X) &=& \displaystyle \sum_{x_i \in X(\Omega)} x_i P(X = x_i) &=& \displaystyle 1 \times {1 \over 3} + 2 \times {1 \over 3} + 3 \times {1 \over 3} = 2 \\
\\ \hline \\
V(X) &=& E \left( (X - E(X))^2 \right) &=& \displaystyle \sum_{x_i \in X(\Omega)} (x_i - E(X))^2 P(X = x_i) \\ \\
& & &=& \displaystyle {1 \over 3} + 0 + {1 \over 3} = {2 \over 3} \\ \\
& =&E(X^2) - E(X)^2 &=& \displaystyle \sum_{x_i \in X(\Omega)} x_i^2 P(X = x_i) - E(X)^2 \\ \\
& & &=& \displaystyle 1^2 \times {1 \over 3} + 2^2 \times {1 \over 3} + 3^2 \times {1 \over 3} - 2^2 \\ \\
& & &=& \displaystyle {14 \over 3} - 4 = {2 \over 3} \\
\\ \\ \hline \\
\sigma_X &=& \sqrt{V(X)} &=& \sqrt{2 \over 3}
\end{array}
$$

> ### $X$ suit la loi de Bernoulli de paramètre ${1 \over 3} : X \sim \mathcal B \left( 1, {1 \over 3} \right)$

$$ X(\Omega) = \left \{ \underbrace 0_{\sixptsize \text{succès}}, \underbrace 1_{\sixptsize \text{échec}} \right \} $$

Loi de probabilité :

$$ \begin{aligned}
 P(X = 0) &= 1 - p = {2 \over 3} \\
P(X = 1) &= p = {1 \over 3} 
\end{aligned}$$

Fonction de répartition :

$$ 
F(x) = \left \{ \begin{aligned}
0 &:x < 0 \\
{2 / 3} &:x \in [0, 1[ \\
1 &: x \geqslant 1
\end{aligned} \right.
$$ ![](https://i.imgur.com/SO823F4.png)
$$\sixptsize [ \color{#D32F2F}{\text{Loi de probabilité}} \ \color{default} {;}  \ \color{#1565C0}{\text{Fonction de répartition}} \color{default} ]$$

$$
\begin{aligned}
E(X) &= 0 \times {2 \over 3} + 1 \times {1 \over 3} = {1 \over 3} \\
V(X) &= 0^2 \times {2 \over 3} + 1^2 \times {1 \over 3} -\left( 1 \over 3 \right)^2 = {2 \over 9} \\
\sigma_X &= \sqrt{2 \over 9} = {\sqrt 2 \over 3}
\end{aligned}
$$

> ### $X$ suit la loi binomiale de paramètres $n = 3$ et $p = 4 : X \sim \mathcal B \left(3 , {1 \over 4} \right)$

$$ X \sim \mathcal B \left ( \begin{matrix}
n & , & p \\
\underbrace {}_{\sixptsize \begin{gathered} \text{nb. d'épreuves} \\ \text{de Bernoulli} \end{gathered}} & & \underbrace {} _{\sixptsize \begin{gathered} \text{prob.} \\ \text{de succès} \end{gathered}}
 \end{matrix}  \right )$$

  ```mermaid
 graph TD
 A(" ") -->|1 - p|B(0)
 A -->|p|C(1)
 B -->|1 - p|D(0)
 B -->|p|E(1)
 C -->|1 - p|F(0)
 C -->|p|G(1)
 D -->|1 - p|H(0)
 D -->|p|I(1)
 E -->|1 - p|J(0)
 E -->|p|K(1)
 F -->|1 - p|L(0)
 F -->|p|M(1)
 G -->|1 - p|N(0)
 G -->|p|O(1)
```
 
 $$ X(\Omega) = \{0, 1, 2, 3 \} $$ $$ \footnotesize \begin{array}{c|c} \begin{aligned}
P(X = i) &= C_n^i p^i (1 - p)^{n - i} \\
P(X = 0) &= \left ( 3 / 4 \right )^3 = {27 / 64} \\
P(X = 1) &= 3 \times {1 / 4} \times \left ( 3 / 4 \right )^2 = {27 / 64}  \\
P(X = 2) &= 3 \times \left ( 1 / 4 \right ) ^2 \times {3 / 4} = {9 / 64} \\
P(X = 3) &= \left ( 1 / 4 \right )^3 = {1 / 64}
\end{aligned} & F(x) = \left \{ \begin{aligned}
0 &: x <  0 \\
{27 / 64} &: x \in [0, 1[ \\
{54 /64} &: x \in [1, 2[ \\
{63 /64} &: x \in [2, 3[ \\
1 &:x \geqslant 3
\end{aligned} \right.  \end{array}$$

$$ $$

![](https://i.imgur.com/52XG1ZW.png) $$\sixptsize [ \color{#D32F2F}{\text{Loi de probabilité}} \ \color{default} {;}  \ \color{#1565C0}{\text{Fonction de répartition}} \color{default} ]$$

$$
\begin{aligned}
E(x) &= np = 3 \times {1 \over 4} = {3 \over 4} \\
V(x) &=np (1 - p) = npq = {3 \over 4} \times {3 \over 4} = {9 \over 16} \\
\sigma_X &= \sqrt{npq} = \sqrt{9 \over 16} = {3 \over 4}
\end{aligned}
$$

## Exercice 6 - Loi binomiale

> L'expérience montre que 20% des personnes qui réservent une table dans un restaurant ne donnent pas suite.
> Un restaurant possède 50 tables. Il accepte 53 réservations. Quelle est la probabilité pour que cela ne se passe pas bien ?

$$ \scriptsize\begin{alignedat}{2} &X \sim \mathcal B \left (53, {4 \over 5} \right ) :
P(X > 50) &&= P(X = 51) + P(X = 52) + P(X =53) \\
& &&= 1 - P(\overline{X >50}) = 1 - P(X \leqslant 50) = 1 - F(50) \\
&X \sim \mathcal B \left (53, {1 \over 5} \right ) : P(X < 3) &&= P(X \leqslant 2) \\
& &&\approx 0,07 \%
\end{alignedat}$$

## Exercice 7 - Loi conjointe

> On lance deux fois un dé tétraédrique parfait numéroté de 1 à 4. $X$ est le premier numéro lu sur la base, $Y$ le deuxième et $M$ le plus petit des deux.
> ### Construire la loi conjointe de $X$ et $Y$, en précisant les lois marginales de $X$ et de $Y$.

$X \backslash Y$ | $1$ | $2$ | $3$ | $4$ | $P(X = i)$
-|-|-|-|-|-
$1$ | $1/16$ | $1/16$ | $1/16$ | $1/16$ | $1/4$
$2$ | $1/16$ | $1/16$ | $1/16$ | $1/16$ | $1/4$
$3$ | $1/16$ | $1/16$ | $1/16$ | $1/16$ | $1/4$
$4$ | $1/16$ | $1/16$ | $1/16$ | $1/16$ | $1/4$
$P(Y = j)$ | $1/4$ | $1/4$ | $1/4$ | $1/4$

> ### Faire de même pour le couple $(X, M)$.
$$ \begin{aligned}
P((X = 1) \cap (M = 1)) &= P(\{(1,1),(1,2),(1,3),(1,4)\} \\ 
&= 4 \times {1 \over 16}  = {1 \over 4} \\
P((X = 2) \cap (M = 1)) &= P(\{\}) \\
&= 0
\end{aligned} \\ \dots$$

$X \backslash M$ | $1$ | $2$ | $3$ | $4$ | $P(X = i)$
-|-|-|-|-|-
$1$ | $1/4$ | $0$ | $0$ | $0$ | $1/4$
$2$ | $1/16$ | $1/16$ | $0$ | $0$ | $1/4$
$3$ | $1/16$ | $1/16$ | $1/8$ | $0$ | $1/4$
$4$ | $1/16$ | $1/16$ | $1/16$ | $1/16$ | $1/4$
$P(M = j)$ | $7/16$ | $5/16$ | $3/16$ | $1/16$ | $\} \sixptsize \text{ Loi de prob. de } M$

> ### En déduire la loi de probabilité et la fonction de répartition de $M$. Représenter graphiquement

$$ \begin{array}{c|c} \begin{aligned}
P(M = 1) &= {7 /16} \\
P(M = 2) &= {5 /16} \\
P(M = 3) &= {3 /16} \\
P(M = 4) &= {4 /16}
\end{aligned}  & F_M(x) = \left \{ \begin{aligned}
0 &: x < 1 \\
7/16 &: x \in [1, 2[ \\
3/4 &: x \in [2, 3[ \\
15/16 &: x \in [3, 4[ \\
1 &: x \geqslant 4
\end{aligned} \right. \end{array}$$

![](https://i.imgur.com/8RiT18u.png)$$\sixptsize [ \color{#D32F2F}{\text{Loi de probabilité}} \ \color{default} {;}  \ \color{#1565C0}{\text{Fonction de répartition}} \color{default} ]$$

> ### $X$ et $Y$ sont-elles indépendantes ? Même question pour $X$ et $M$.

$X$ et $Y$ indépendantes : $\forall \ i \ \forall j \ P((X = i) \cap (Y = j)) = P(X = i) \times P(Y = j)$

Ici, $\forall \ i \ \forall \ j \ \underbrace{P((X = i) \cup (Y = j))}_{1/16} = \underbrace {P(X=i)}_{1/4} \times \underbrace {P(Y = j)}_{1/4}$

$X$ et $M$ non-indépendantes : $\underbrace{P((X=4) \cap (M = 4))}_{1/16}  \neq \underbrace{P(X = 4)}_{1/4} \times \underbrace{P(M = 4)}_{1/16}$

> ### Calculer $E(X)$, $E(Y)$ et $E(M)$, puis $V(X)$, $V(Y)$ et $V(M)$.

$$\footnotesize\begin{aligned}
E(X) = E(Y) &= 1 \times {1 \over 4} + 2 \times {1 \over 4} + 3 \times {1 \over 4} + 4 \times {1 \over 4}  = {5 \over 2} \\
E(M) &= 1 \times {7 \over 16} + 2 \times {5 \over 16} + 3 \times {3 \over 16} + 4 \times {1 \over 16} = {15 \over 18} \\
V(X) = V(Y) &= E(X^2) - E(X)^2 \\
&= 1^2 \times {1 \over 4} + 2^2 \times {1 \over 4} + 3^2 \times {1 \over 4} + 4^2 \times {1 \over 4} - \left ( 5 \over 2 \right )^2 \\
&= {5 \over 4} \\
V(M) &= 1^2 \times {7 \over 16} + 2^2 \times {5 \over 16} + 3^2 \times {3 \over 16} + 4^2 \times {1 \over 16} - \left (15 \over 8 \right )^2 \\
&={55 \over 64}
\end{aligned} $$

> ### Préciser les lois de probabilité de $Z_1 = X + Y$ et de $Z_2 = X + M$.

$$ Z_1(\Omega) = Z_2(\Omega) = \{2,3,4,5,6,7,8\} 
(= [\![2, 8]\!]) $$

$$
\begin{array}{c|c} 
\footnotesize \begin{gathered} \begin{alignedat}{2}
P(Z_1 = 2) &= P(X = 1) \times P(Y = 1) &&= 1/16 \\
P(Z_1 = 3) &= P(X = 1) \times P(Y = 2) && \\
& + P(X = 2) \times P(Y = 1) &&= 1/8
\end{alignedat} \\ \footnotesize \begin{aligned}
P(Z_1 = 4)  = \dots  &= 3/16 \\
P(Z_1 = 5)  &= 1/4 \\
P(Z_1 = 6)  &= 3/16 \\
P(Z_1 = 7)  &= 1/8 \\
P(Z_1 = 8)  &= 1/16
\end{aligned} \end{gathered} & \footnotesize \begin{aligned}
P(Z_2 = 2) &= 1/4 \\
P(Z_2 = 3) &= 1/16 \\ \\ 
P(Z_2 = 4) &= 1/4 \\
P(Z_2 = 5) &= 1/8 \\
P(Z_2 = 6) &= 3/16 \\
P(Z_2 = 7) &= 1/16 \\
P(Z_2 = 8) &= 1/16 \\
\end{aligned}
\end{array}
$$

> ### Calculer $E(Z_1)$ et $E(Z_2)$, puis $V(Z_1)$ et $V(Z_2)$.

$$\begin{aligned} 
E(X + Y) &= E(X) + E(Y) \\
V(X + Y) &= V(X) + V(Y) \text{ si }X, Y \text{ indépendantes}.
\end{aligned} \\ $$$$\begin{array}{c|c} \begin{aligned}
E(Z_1) &= 5 \\
E(Z_2) &= 35/8 \\
~ \\
~ \\
~
\end{aligned} & \begin{aligned}
V(Z_1) &= 5/2 \\
V(Z_2) &=E((Z_2)^2) - E(Z_2)^2 \\
 & \sixptsize = 2^2 \times1/4 + 3^2 \times 1/16 + 4^2 \times 1/4 + 5^2 \times 1/8 \\
 & \sixptsize + 6^2 \times 3/16 + 7^2 \times 1/16 + 8^2 \times 1/16 - (35/8)^2 \\
 & \sixptsize = 215/64
\end{aligned}
 \end{array}$$

> ### Préciser les lois de probabilité de $Z_3 = XY$ et de $Z_4 = XM$.

$$ \begin{aligned}
Z_3(\Omega) = Z_4(\Omega) &= \sixptsize \{4 \times 4, 4 \times 3,4 \times 2,4 \times 1,3 \times 3,3 \times 2,3 \times 1,2 \times 1,1 \times 1\} \\
&= \{1,2,3,4,6,8,9,12,16\}
\end{aligned}$$

$i$ | $1$ | $2$ | $3$ | $4$ | $6$ | $8$ |  $9$ | $12$ | $16$
-|-|-|-|-|-|-|-|-|-
$P(Z_3 = i)$ | ${1\over16}$ | ${1\over8}$ | ${1\over8}$ | ${3\over16}$ | ${1\over8}$ | ${1\over8}$ | ${1\over16}$ | ${1\over8}$ | ${1\over16}$
$P(Z_4 = i)$ | ${1\over4}$ | ${1\over16}$ | ${1\over16}$ | ${1\over4}$ | ${1\over16}$ | ${1\over16}$ | ${1\over8}$ | ${1\over16}$ | ${1\over16}$

> ### Calculer $E(Z_3)$ et $E(Z_4)$, puis $V(Z_3)$ et $V(Z_4)$.

$$ E(XY) = E(X) \times E(Y) \text{ si } X,Y \text{ indépendantes}.$$ $$\begin{alignedat}{2}
 E(Z_3) &= {5 / 2} \times {5 / 2} &&=  {25 / 4} \\
 E(Z_4) &= 1 \times {1/4} + \dots + 16 \times {1/16} &&= 85/16
\end{alignedat}  $$ $$
\begin{alignedat}{2}
V(Z_3) &= 1^2 \times 1/16 + \dots + 16^2 \times 1/16 - (25/4)^2 &&= 275/16  \\
V(Z_4) &= 1^2 \times 1/4 + \dots +16^2 \times 1/16 &&= 4553/256
\end{alignedat}
$$

>### Calculer $\operatorname{cov}(X,Y)$ et $\operatorname{cov}(X,M)$.
>$$ \begin{aligned}
&\operatorname{cov}(X,Y) = E((X - E(X))(Y-E(Y)) \\
&\operatorname{cov}(X,Y) = E(XY) - E(X)E(Y) \\
&\operatorname{cov}(X,X) = V(X) \\
&\operatorname{cov}(X,Y) =0 \text{ si } X,Y \text{ indépendants}.
\end{aligned}$$ 

$$
\begin{aligned}
&\operatorname{cov}(X,Y) =0 \\
&\operatorname{cov}(X,M) = 85/16 -5/2 \times 15/8 = 5/8
\end{aligned}
$$

## Exercice 8 - Loi faible des grands nombres

> Avant une élection nationale, on interroge un échantillon de $n$ personnes sur leur intention de vote pour un parti donné. On note $\overline X$ la proportion de personnes favorables à ce parti dans l'échantillon.
> ### Déterminer une valeur minimale de $n$ permettant d'estimer  à 3% près, avec un risque d'erreur inférieur à 5%, la proportion $\pi$ d'électeurs votant pour ce parti.
> $P(\lvert \overline X - \pi \rvert < 0,03) \geqslant 0,95$
> > * Soient $X_1, X_2, \dots, X_n$ $n$ variables aléatoires indépendantes relatives à une suite de $n$ expériences aléatoires identiques. L’espérance commune est notée $m$ et l'écart-type $\sigma$.
> > Alors $P \left( \lvert {{X_1 + X_2 + \dots + X_n} \over {n}} - m \rvert \geqslant \epsilon \right ) \leqslant {\sigma^2 \over {n \epsilon ^2}}$.
> > $X_i \sim \mathcal B(1, \pi), (1 \leqslant i \leqslant n)$
> >
> > * $\sigma_{X_i}^2 = \pi (1 - \pi) \leqslant {1 \over 4}$ sur $[0,1]$.
> >
> > * On veut obtenir $P(\lvert \overline X - \pi \rvert < 0,03) \geqslant 0,95$, c'est à dire $P \left ( \lvert {{X_1 + \dots + X_n} \over n} - \pi \rvert \geqslant 0,03 \right ) \leqslant 1 - 0,95 = 0,05$.
> > En prenant $m = \pi$, $\sigma^2 = \pi(1 - \pi)$ et $\epsilon = 0,03$, 
> > $P\left ( \lvert {{X_1 + \dots + X_n} \over n} - m \rvert \geqslant \epsilon \right ) \leqslant {\sigma^2 \over {n \epsilon^2}}$ s'écrit $P(\lvert \overline X - \pi \rvert \geqslant 0,03) \leqslant {{\pi ( 1 - \pi)} \over {n \times 0,03^2}}$.
> > On a alors $P( \lvert \overline X - \pi \rvert \geqslant 0,03) \leqslant {{\pi (1 - \pi)} \over {n \times 0,03^2}} \leqslant {{1/4} \over {n \times 0,03^2}}$.
> >Pour obtenir $P(\lvert \overline X - \pi \rvert < 0,03) \geqslant 0,95$, il suffit de prendre $n$ vérifiant ${1 \over {4n \times 0,03^2}} \leqslant 0,05$.

![](https://i.imgur.com/l2Lefvp.png)

$$ \overline X = {{X_1 + \dots + X_n} \over n} $$

Loi des grands nombres : $P(\lvert \overline X - \pi \rvert \geqslant \epsilon) \leqslant {{V(\overline X)} \over \epsilon^2}$

$$\begin{array}{c|c}
V(\overline X) = {{\pi (1 - \pi)} \over n} & \pi = ? \\
~ \\
\hline
~ \\
f(x) = x(1 - x) & f'(x) = 1 - 2x
\end{array}$$

$$\begin{array}{|c|ccccr|}
\hline
x & 0 & & 1/2 & & 1 \\
\hline
f'(x) &  & + & 0 & - \\
\hline
 & & & 1/4 \\       % ligne des valeurs "max"
f(x) &  &\nearrow   & & \searrow \\   % flèches
& 0 & & & & 0 \\          % ligne des valeurs "min"
\hline
\end{array}$$

$$\footnotesize\begin{aligned}
P(\lvert \overline X - \pi \rvert < 0,03) \geqslant 0,95 &\iff 1 - P(\overline{\lvert \overline X - \pi \rvert < 0,03}) \geqslant 0,95  \\
&\iff1 - P(\lvert \overline X - \pi \rvert \geqslant 0,03) \geqslant 0,95  \\
&\begin{aligned}
\ \iff P(\lvert \overline X - \pi \rvert \geqslant 0,03) \leqslant \ &1 - 0,95 \\
&= 0,05
\end{aligned} \\
&\implies n \geqslant {1 \over {4 \times 0,03^2 \times 0,05}} = 5555,5 \dots
\end{aligned}$$

## Exercice 9 - Intervalle de fluctuation

> Une petite ville des États-Unis, Woburn, a connu 9 cas de leucémie parmi les 5 969 garçons de moins de 15 ans sur la période 1969-1979. La fréquence des leucémies pour cette tranche d'âge aux États-Unis est égale à 0,00052. 
> *Source : Massachussets Department of Public Health*
> Les autorités concluent qu'il n'y a rien d'étrange dans cette ville. Qu'en penser ?
> Pour pouvoir répondre à la question, on suppose que dans la population des garçons de moins de 15 ans de Woburn, la fréquence des leucémies est égale à $p = 0,00052$. Le nombre $X$ de garçons de moins de 15 ans de Wobern atteints de leucémie suit alors la loi hypergéométrique
> $$ \mathcal H(N,n,p) : \forall \ i \in X(\Omega), P(X = i) = {{C_{N_1}^i C_{N_2}^{n - i}} \over C_N^n} $$
> avec $N_1 = Np$, $N_2 = N - N_1$.
> ![](https://i.imgur.com/QN7rUI1.png)
> $$(N_1 = 10 \ 400  \ ; \ N = 20 \ 000 \ 000 \ ; \\ p = {N_1 \over N} = 0,00052) \ ; \ n = 5 \ 969)$$  On pose $i_W = 9$.
> ### Préciser l'expression, puis la valeur de $P(X = i_W)$.

$$ X \sim \mathcal H(N,n,p) : P(X = i_W) = {{C_{10 \ 400} ^9 C_{19 \ 989 \ 600}^{5 \ 960}} \over {C_{20 \ 000 \ 000}^{5 \ 960}}} = 3,30 \cdot 10^{-3} $$

> ### Vérifier qu'on peut approcher la loi hypergéométrique $\mathcal H(N,n,p)$, avec $p = {N_1 \over N}$, par la loi binomiale $\mathcal B(n,p)$.
> > L'approximation est satisfaisante si ${n \over N} < 0,05$.

$$ {n \over N} = {{5 \ 969} \over {20 \ 000 \ 000}} \approx 0,00029845 \ll 0,05 $$ $$ \implies \mathcal H (N,n,p) \approx \mathcal B(n,p) $$

> ### Préciser l'expression, puis la valeur de $P(X = i_W)$.

$$ \scriptsize \begin{alignedat}{2}
&X \sim \mathcal B(n, p) : P(X = i_W) &&= C_{5 \ 969}^9 \times \left (5,2 \cdot 10^{-4} \right )^9 \times \left (1 - \left (5,2 \cdot 10^{-4} \right ) \right )^{5 \ 960} \\
 & &&\approx 0,00330
\end{alignedat}$$

> ### Intervalle de fluctuation

> #### Déterminer l'intervalle de fluctuation $[\![n_1, n_2 ]\!]$ au seuil de risque $\alpha = 0,05$ (ou de niveau $1 - \alpha$) qui est le plus petit intervalle $[\![n_1, n_2]\!]$ tel que $P(X < n_1) \leqslant {\alpha \over 2}$ et $P(X > n_2) \leqslant {\alpha \over 2}$.
> > On a alors $P(n_1 \leqslant X \leqslant n_2) \geqslant 1 - \alpha$.

$$ \sixptsize\begin{array}{c|c}
\begin{aligned}
\left. \begin{aligned}
P(X < n_1) &\leqslant {\alpha \over 2} \\
P(X > n_2) &\leqslant {\alpha \over 2}
\end{aligned} \right \} &= 0,025 \\
\left. \begin{aligned}
F(n_1 - 1) = P(X \leqslant n_1 - 1) &\leqslant {\alpha \over 2} \\
F(n_1) = P(X \leqslant n_1) &> {\alpha \over 2}
\end{aligned} \right \} &= 0,025 \\
~ \\
~ \\
~ \\
\end{aligned} &
\begin{aligned}
\left. \begin{aligned}
P(X >n_2) &\leqslant {\alpha \over 2} \\
P(X > n_2 - 1) &> {\alpha \over 2}
\end{aligned} \right \} &= 0,025 \\
\left. \begin{aligned}
1 - P(X \leqslant n_2) &\leqslant {\alpha \over 2} \\
1 - P(X \leqslant n_2 - 1) &> {\alpha \over 2}
\end{aligned} \right \} &= 0,025 \\
\left. \begin{aligned}
F(n_2) &\geqslant 1 - {\alpha \over 2} \\
F(n_2 - 1) &< 1 - {\alpha \over 2}
\end{aligned} \right \} &= 0,975 \\
\end{aligned} \\
F(0) \approx 0,04482 > 0,025 \implies n_1 = 0  &
\begin{aligned}
F(6) &\approx 0,96105 < 0,975 \\
F(7) &\approx 0,98573 \geqslant 0,975 \\
\end{aligned} \implies  n_2 = 7
\end{array} $$ $$ \text{Intervalle de fluctuation : } [\![0,7]\!] $$

> #### Que constate-t-on ? Est-ce que $i_W \in [\![n_1, n_2]\!]$ ?

$$ 9 \notin [\![0,7]\!], 9\in [\![8,5969]\!] $$

> #### Calculer $P(n_1 \leqslant X \leqslant n_2)$.

$$ P(0 \leqslant X \leqslant 7) = F(7) \approx 98,6 \%$$

> #### Préciser $P(X \geqslant i_W)$. Interpréter le résultat.

$$ \begin{aligned}
P(X \geqslant 9) &= 1 - P(X < 9) = 1 - P(X \leqslant 8) \\ 
&= 1 - 0,99530 \\
&\approx 0,47\%
\end{aligned}$$ On déduit de ce résultat que le constat des autorités, selon lequel il n'y a pas lieu de s'inquiéter, est incorrect.

> On peut aussi envisager un intervalle de fluctuation unilatéral au seuil de risque $\alpha = 0,05$ : le plus petit intervalle $[\![0, n'_2]\!]$ tel que $P(X > n'_2) \leqslant \alpha$.
> #### Préciser $n'_2$ et $[\![0, n'_2]\!]$. Est-ce que $i_W \in [\![0, n'_2]\!]$ ?

$$
\begin{aligned}
F(n_2 - 1) &< 0,95 \\
F(n_2) &\geqslant 0,95
\end{aligned}
\implies n'_2 = 6 \\ $$ $$
i_W \notin [\![0,6]\!]
$$

> ### Vérifier qu'on peut aussi approcher la loi binomiale $\mathcal B(n, p)$ par une loi de Poisson $\mathcal P(\lambda)$ dont on précisera $\lambda$ et l'expression de $P(X = i) (i \geqslant 0)$.
> > L'approximation est satisfaisante si $n \geqslant 30$ ; $p \leqslant 0,1$ ; $np \leqslant 10$ ; $i$ petit devant $n$ (événements rares).

$$
\left. \begin{aligned}
&n = 5969 \gg 30 \\
&p = 0,00052 \ll 0,1 \\
&np \approx 3,1 \leqslant 10 \\
&i_W =9 < n = 5969
\end{aligned} \right \} \implies
\mathcal B(n,p) \approx \mathcal P(np)
$$ $$\begin{alignedat}{2}
 X \sim \mathcal P(\lambda) : \ &P(X = i_W)  &&= e^{-\lambda} {\lambda^i_W \over i_W !} \\
 & &&\approx e^{-3,1} {3,1^9 \over {9!}} \approx 0,33 \%\\
 & P(X \geqslant i_W) &&= 1 - P(X < i_W) = 1 - P(X \leqslant i_W - 1) \\
 & &&= 1 - P(X \leqslant 8) = 1 - F(8) \\
 & &&\approx 0,47 \%
 \end{alignedat}$$
 
> ### Comparer les différentes valeurs de $P(X \geqslant i_W)$ suivant la loi utilisée.

Loi | hypergéométrique | binomiale | de Poisson
-|-|-|-
$P(X \geqslant i_W)$ | $0,47 \%$ | $0,47 \%$ | $0,47 \%$

> ## Variables aléatoires absolument continues

## Exercice 10 - Loi uniforme

> On propose à une personne de couper en deux un ruban de 10 cm de long. La variable aléatoire $X$ précisant l'endroit de la découpe suit la loi uniforme sur $[0,10] : X \sim \mathcal U_{[0,10]}$.
> Préciser :
> ### Densité de probabilité $f(x)$

$$\begin{aligned} X \sim \mathcal U([a,b]) : f(x) &= \left \{ \begin{aligned}
0 &: x \in \ ] -\infin, a[  \ \cup \ ]b, +\infin[ \\
{1 \over {b - a}} &: x \in [a, b]
\end{aligned} \right. \\ \\
X \sim \mathcal U([0,10]) : f(x) &= \left \{ \begin{aligned}
{1 \over 10} &: x \in [0,10] \\
0 &\text{ ailleurs}
\end{aligned} \right. \end{aligned}$$

> ### Fonction de répartition $F(x) = P(X \leqslant x)$

$$\footnotesize\begin{aligned} F(x) &= P(X \leqslant x) = \int_{-\infin}^x f(t) \ dt \\
&= \left \{ \begin{aligned}
0 &: x < 0 \\
\hline \\
\int_{- \infin}^0 0 \ dt + \int_0^x {1 \over 10} \ dt = \left [ {1 \over 10} t \right ]_0^x &: 0 \leqslant x \leqslant 10 \\ \\
\hline \\
0 + \int_0^{10} {1 \over 10} t \ dt + \int_{10}^x 0 \ dt = \left [ {1 \over 10} t \right ]_0^{10} &: x > 10
\end{aligned} \right. \\
~ \\
&= \left \{ \begin{aligned}
0 &: x < 0 \\
{1 \over 10} x &: 0 \leqslant x \leqslant 10 \\
1 &: x > 10
\end{aligned} \right. \end{aligned}$$

> ### Probabilité que la découpe se fasse à moins de 3 cm de l'extrémité gauche

$$ P(X \leqslant 3) = F(3) = {3 \over 10} = 30 \% $$

> ### Probabilité que la découpe se fasse en un point situé à plus de 4 cm et à moins de 5 cm de l'extrémité gauche

$$ P(X \leqslant X \leqslant 5) = F(5) - F(4) = {5 \over 10} - {4 \over 10} = 10 \% $$

> ### Probabilité que la découpe se fasse en un point situé à au moins 6 cm de l'extrémité gauche

$$\begin{aligned} 
P(X \geqslant 6) &= 1 - P(\overline {X \geqslant 6}) = 1 - P(X \leqslant 6) = 1 - F(6) \\
&= 1 - {6 \over 10} = 40\%
\end{aligned}$$

> ### Point de découpe à partir de l'extrémité gauche correspondante à une probabilité d'au moins 95%

$$\begin{alignedat}{2}
F(x) &\geqslant 0,95 \  (&&\iff P(X \leqslant x) \geqslant 0,95) \\
{1 \over 10} x &\geqslant 0,95 &&\iff x \geqslant 9,5 \text{ cm}
\end{alignedat}$$

> ### $E(X)$, $V(X)$ et $\sigma_X$
> > $\displaystyle \scriptsize E(X) = \int_{- \infin}^{+ \infin} x f(x) \ dx$ et $\scriptsize V(X) = E((X - E(X))^2) = E(X^2) - E(X)^2$ si elles existent.

$$ \footnotesize \begin{array}{rcccl}
E(X) &=& \displaystyle \int_{-\infin}^{+\infin} x f(x) \ dx &=& \displaystyle \int_{- \infin}^0 x \times 0 \ dx + \int_0^{10} x \times {1 \over 10} \ dx +  \int_{10}^{+ \infin}x \times 0 \ dx \\ \\
& & &=& \displaystyle 0 + {1 \over 10} \int_0^{10} x \ dx + 0 \\ \\
& & &=& \displaystyle {1 \over 10} \left [ {1 \over 2} x^2 \right ]_0^{10} = {50 \over 10} = 5 \\ \\ \hline \\ 
V(X) &=& E(X^2) - E(X) &=& \displaystyle \int_0^{10} {1 \over 10} x^2 \ dx - 25 \\ \\
& & &=& \displaystyle {1 \over 10} \int_0^{10} x^2 \ dx - 25 \\ \\
& & &=& \displaystyle {1 \over 10} \left [ {1 \over 3} x^3 \right ]_0^{10} - 25 \\ \\
& & &=& \displaystyle {100 \over 3} - 25 = {25 \over 3} \\ \\ \hline \\ 
\sigma_X &=& \sqrt {V(X)} &=& \displaystyle {{5 \sqrt 3} \over 3}
\end{array} $$

> ### Représentation graphique

![](https://i.imgur.com/eorTwBe.png)
$$\sixptsize [ \color{#D32F2F}{\text{Loi de probabilité}} \ \color{default} {;}  \ \color{#1565C0}{\text{Fonction de répartition}} \color{default} ] \\
\sixptsize[\color{#2E7D32} P(X \leqslant 3) \color{default} \ ; \color{#DB6114} P(4 \leqslant X \leqslant 5) \color{default} \ ; \color{#6557D2} P(X \geqslant 6) \color{default} \ ; \color{#000000} P(X \leqslant x) \geqslant0,95 \color{default}]
$$

## Exercice 11 - Loi exponentielle

> La variable  aléatoire $X$ précisant le temps d'attente en minutes d'un taxi suit la loi exponentielle de paramètre $a = 1 : X \sim \mathcal E (1)$.
> Préciser :
> ### Densité de probabilité $f(x)$

$$ \begin{aligned}
&f(x) = \left \{ \begin{aligned} 
&ae^{-ax} \text { sur } [0, +\infin[ \\
&0 \text{ ailleurs}
\end{aligned} \right. \\ \\
\implies &f_a(x) = e^{-x}
\end{aligned} $$

> ### Fonction de répartition $F(X) = P(X \leqslant x)$

$$\begin{array}{c} \displaystyle F(x) = P(X \leqslant x) = \int_{-\infin}^x f(t) \ dt \\ \\\hline \\
\begin{array}{lcl|lcl}
\overline {\underline{x \geqslant 0 }} &=& \displaystyle \int_{-\infin}^x a e^{-at} \ dt & \overline{\underline{x < 0}} &=& \displaystyle \int_{- \infin}^x 0 \ dt \\ \\
&=& a \left [ - {e^{-a t} \over a} \right ]_0^x & &=& 0 \\ \\
&=&a \left ( - {e^{-ax} \over a} - \left ( - {e^{a \times 0} \over a} \right )  \right ) \\ \\
&=& a \left ( - {e^{-ax} \over a} + {1 \over a} \right ) \\ \\
&=& - e^{-ax} + 1 \\ \\
\overline{\underline{a = 1}} &=&1 - e^{-x}
\end{array} \end{array}$$

> ### Probabilité qu'un taxi arrive au bout de 1 minute au plus

$$ P(X \leqslant 1) = F(1) = 1 -  e^{-1} \approx 63,2\%$$

> ### Probabilité qu'un taxi arrive après un temps d'attente compris entre 1 et 5 minutes

$$ P(1 \leqslant X \leqslant 5) = F(5) - F(1) = 1 - e^{-5} - 1 + e^{-1} \approx 36,1 \% $$

> ### Probabilité qu'un taxi arrive après un temps d'attente compris entre 0,5 et 1,5 minutes

$$ P(0,5 \leqslant X \leqslant 1,5) = 1 - e^{-1,5} - 1 + e^{-0,5} \approx  38,3 \% $$

> ### Temps d'attente correspondant à une probabilité d'au moins 95%

$$ \begin{array}{lcrcl}
P(X \leqslant x) \geqslant 0,95 &\iff& 1 - e^{-x} &\geqslant&  0,95 \\
&\iff& -e^{-x} &\geqslant&  - 0,05 \\
&\iff& e^{-x} &\leqslant& 0,05 \\
&\iff& -x &\leqslant& \ln(0,05) \\
&\iff& x &\geqslant& - \ln(0,05) \approx 3 \text{ min}
\end{array} $$

> ### $E(X)$, $V(X)$ et $\sigma_X$

$$ E(X) = {1 \over a} = 1 \ ; \ V(X) = {1 \over a^2} = 1 \ ; \ \sigma_X =  \sqrt {1 \over a^2} = 1 $$

> ### Représentation graphique

![](https://i.imgur.com/QjUXavM.png)
$$\sixptsize [ \color{#D32F2F}{\text{Loi de probabilité}} \ \color{default} {;}  \ \color{#1565C0}{\text{Fonction de répartition}} \color{default} ] \\
\sixptsize[\color{#6557D2} P(X \leqslant 1) \color{default} \ ; \color{#2E7D32} P(1 \leqslant X \leqslant 5) \color{default} \ ; \color{#DB6114} P(0,5 \leqslant X \leqslant 1,5) \color{default}]
$$


## Exercice 12 - Approximation d'une loi binomiale

> Une ligne de transmission entre émetteur et récepteur transporte des pages de texte, chaque page étant représentée par 100 000 bits (caractères, informations de transmission et de contrôle). La probabilité qu'un bit soit erroné est estimée à 0,0001 et on admet que les erreurs sont indépendantes les unes des autres.
> Soit $X$ la variable aléatoire associant à chaque page transportée le nombre d'erreurs lors de la transmission de la page.
> 
> #### Quelle est la loi suivie par la variable aléatoire $X$ ?

$$ X \sim \mathcal B(10^5, 10^{-4}) $$ $$ P(X = i) = C_{10^5} ^i (10^{-4})^i $$

> #### Donner la moyenne et l'écart-type de $X$.

$$ \begin{aligned}
E(X) &= np = 10^5 \times 10^{-4} = 10 \\
V(X) &= npq = 10 \times (1 - 10^{-4}) =  9,999 \\
\sigma_X &= \sqrt{npq} \approx 3,162
\end{aligned} $$

> ### Approximation par une loi de Poisson

> #### Vérifier que  la loi peut-être approchée par une loi de Poisson.
> > L'approximation de la loi binomiale $\mathcal B(n,p)$ par la loi de Poisson $\mathcal P(\lambda)$ avec $\lambda = np$ est envisageable pour $n$ assez grand $(n \geqslant 30)$, $p \leqslant 0,1$ et $np \leqslant 10$.

> #### Déterminer le paramètre de cette loi.
> 
$$ \footnotesize \left. \begin{alignedat}{3}
10^5  &\gg30 &&\implies n &&\geqslant 30 \\
10^{-4} &\ll0,1 &&\implies  p &&\leqslant 0,1 \\
10 &\leqslant 10 &&\implies np &&\leqslant 10
\end{alignedat} \right \rvert\begin{gathered}
\\
\implies \mathcal B(n =10^5, p =10^{-4}) \approx P(\lambda = 10) \\
\lambda = E(X) \approx V(X)
\end{gathered}  $$

> #### Dans ces conditions, déterminer la probabilité qu'une page comporte au plus 15 erreurs.

$$\begin{aligned} 
&P(X = i) = e^{-10} {10^i \over {i!}} (i \geqslant 0) \\
\implies &P(X \leqslant 15) = \sum_{i = 0}^{15} e^{-10} {10^i \over {i!}} \approx 95,1 \% 
\end{aligned}$$

> ### Approximation par une loi normale
> > On décide d'approcher la loi de variable aléatoire discrète $X$ par une loi normale. On note $Y$ une variable aléatoire suivant cette loi $\mathcal N(m, \sigma)$.

> #### Vérifier que la loi peut être approchée par une loi normale.
> > D'après le théorème central limite, l'approximation de la loi binomiale $\mathcal B(n, p)$ par la loi normale $\mathcal N(m, \sigma)$ avec $m = np$ et $\sigma^2 = np(1 - p)$ est envisageable pour $n$ assez grand $(n \geqslant 30)$, $np \geqslant 5$ et $n(1 - p) \geqslant 5$.

$$\begin{array}{c|c|c}
\begin{gathered} n = 100 \ 000 \\ ~ \end{gathered}
& \begin{aligned}
np &= 10^5 \times 10^{-4} \\
&= 10
\end{aligned} & \begin{aligned}
nq &= 10^5 \times (1 - 10^{-4} ) \\
&= 10^5
\end{aligned} \\
n \gg 30 & np \gg 5 & nq \gg 5
\end{array}$$

> #### Préciser les paramètres de cette loi.

$$X \sim \mathcal (m, \sigma)$$ $$m = np = 10$$ $$\sigma = \sqrt {npq} = \sqrt {10^5 \times 10^{-4} \times 0,9999} \approx 3,162$$

$$ \mathcal B (100 \ 000 ; 0,0001) \approx \mathcal N(10 \  ; 3,162) $$

> #### En utilisant cette approximation, déterminer la probabilité qu'une page comporte au plus 15 erreurs, c'est à dire $P(Y \leqslant 15,5)$.

$Y \sim \mathcal N(10  \ ; 3,162)$

$P(Y \leqslant 15,5) = P \left ( {{Y - 10} \over 3,162} \leqslant  {{15,5 - 10} \over 3,162} \right ) = P(T \leqslant 1,739) \approx P(T \leqslant 1,74) \approx 95,9 \%$, $T \sim \mathcal N(0,1)$

$P \left ( {{-0,5 - 10} \over {3,162}} \leqslant T \leqslant 1,74 \right ) = P(-3,32 \leqslant T \leqslant 1,74) = F(1,74) - F(-3,32) = F(1,74) - \underbrace{(1 - F(3,32))}_{5 \cdot 10^{-4}} \approx 95,9 \%$

> #### Comparer les résultats

Loi |Binomiale | Poisson | Normale
-|-|-|-
$P(X \leqslant 15)$ | $95,10\%$ | $95,13 \%$ | $\begin{gathered} 95,91 \% \\ 95,86 \% \end{gathered}$

## Exercice 13 - Approximation d'une loi binomiale par une loi normale

> [[ Suite de l'exercice 8 ]]

> Avant une élection nationale, on interroge un échantillon de $n$ personnes sur leur intention de vote pour un parti donné. On note $\overline X$ la proportion de personnes favorables à ce parti dans l'échantillon.
> ### Déterminer une valeur minimale de $n$ permettant d'estimer à 3% près, avec un risque d'erreur inférieur à 5%, la proportion d'électeurs $\pi$ votant pour ce parti :  $$\footnotesize P(\left \lvert \overline X - \pi \right \rvert < 0,03) \geqslant 0,95$$
> Le nombre de personnes favorables au parti considéré $n \overline X$ suit la loi binomiale $\mathcal B (n, \pi)$ qu'on souhaite approcher par une loi normale.

> #### Préciser les paramètres de la loi normale envisagée et rappeler les conditions d'approximation.

$$\overline X =
 {{X_1 + \dots + X_N} \over n} \implies n \overline X = X_1 + \dots + X_n \sim \mathcal B(n, \pi)$$

$$ n \overline X \sim \mathcal N ( n \pi, \sqrt {n \pi (1 - \pi)} ) \implies {{n \overline X - n \pi} \over \sqrt {n \pi (1 - \pi)}} \sim \mathcal N (0,1)$$

Loi normale - conditions d'approximation :

$$ \mathcal B(n,p) \approx \mathcal N (m, \sigma), \ m = np, \ \sigma^2 = npq  $$


$$\begin{array}{c|c|c}
n \geqslant 30 & np \geqslant 5 & nq \geqslant 5
\end{array}$$



> #### Quelle est la valeur minimale de $n$ obtenue ? Revenir aux conditions d'approximation.

$$ \footnotesize \begin{aligned}
P( \lvert \overline X - \pi \rvert \geqslant 0,95 &\implies P \left ( \left \lvert {{n \overline X - n \pi} \over \sqrt{n \pi (1 - \pi}} \right \rvert < {{0,03 \times n} \over \sqrt {n \pi (1 - \pi)}} \right ) \geqslant 0,95 \\ 
&\iff  P \left ( \lvert T \rvert < {{0,03 \times n} \over \sqrt {n \pi (1 - \pi)}} \right ) \geqslant 0,95, \ T \sim \mathcal N(0,1)
\end{aligned} $$ $$ \scriptsize \begin{aligned} F \left ({ {0,03 \sqrt n} \over \sqrt {\pi(1 - \pi)}} \right ) -  F \left (-{ {0,03 \sqrt n} \over \sqrt {\pi(1 - \pi)}} \right )  &= F \left ({ {0,03 \sqrt n} \over \sqrt {\pi(1 - \pi)}} \right ) - \left ( 1 - F \left ({ {0,03 \sqrt n} \over \sqrt {\pi(1 - \pi)}} \right ) \right ) \\ 
& = 2 F \left ({ {0,03 \sqrt n} \over \sqrt {\pi(1 - \pi)}} \right ) - 1 \geqslant 0,95 \\ 
&\Leftrightarrow F \left ({ {0,03 \sqrt n} \over \sqrt {\pi(1 - \pi)}} \right ) \geqslant  {{1 + 0,95} \over 2} = 0,975 = F(1,96)
\end{aligned} $$
 
> En prenant $\pi (1 - \pi) \leqslant {1 \over 4}$, on a ${{0,03 \sqrt n} \over \sqrt{\pi (1 - \pi)}} \geqslant  {{0,03 \sqrt n} \over \sqrt{1/4}}$

$$\sqrt {\pi ( 1 - \pi)} \leqslant \sqrt {1 \over 4} = {1 \over 2} \implies  {1 \over {\pi (1 - \pi) } } \geqslant 2$$

Or, $\footnotesize F \left ({ {0,03 \sqrt n} \over \sqrt {\pi(1 - \pi)}} \right ) \geqslant F \left ({ {0,03 \sqrt n} \over {1/2}} \right ) \geqslant F(1,96)$. Donc il suffit d'avoir ${{0,03 \sqrt n} \over {1/2}} \geqslant 1,96$ pour obtenir $\footnotesize F \left ({ {0,03 \sqrt n} \over \sqrt {\pi(1 - \pi)}} \right ) \geqslant 0,95$.

$$\begin{aligned} \sqrt n \geqslant {{1,96} \over {2 \times 0,03}}  &\iff n \geqslant \left ( {{1,96} \over {0,06}} \right )^2 \approx 1067,1 \\
&\implies n \geqslant 1068 < 5556 \footnotesize \text{ (Loi des grands nombres)}\end{aligned}$$

Conditions d'approximation :

$$\footnotesize \begin{array}{c|c|c}
\begin{gathered} n \geqslant 30 \\ 
~ \\ ~  \\ ~ \\ ~ \\ 
\end{gathered} ~  & ~  \begin{gathered} n \pi \geqslant 5 \iff \pi \geqslant {5 \over 1068} \\ 
~ \\ ~  \\ ~ \\ ~ \\ 
\end{gathered} ~ & ~ \begin{aligned} n (1 - \pi) \geqslant 5 &\iff n - n \pi \geqslant 5 \\ &\iff n \pi \leqslant n - 5 \\ &\iff \pi \leqslant {{n - 5}\over n} \\ &\iff \pi \leqslant {{1068 - 5} \over 1068} \end{aligned} \\
& \pi \gtrapprox 0,47 \% & \pi \lessapprox 99,53 \%
\end{array}$$

![](https://i.imgur.com/DJ1ijim.png)

> ## Statistique inférentielle

## Exercice 14 - Intervalle de confiance pour une moyenne ; pour un écart-type

> Une entreprise chimique commercialise un polymère servant à la fabrication de microprocesseurs et stocké dans une cuve dont la caractéristique à contrôler est la viscosité. Celle-ci doit être comprise entre 75 et 95 unités pour pouvoir commercialiser le polymère.
> Quatre extractions ont été réalisées dans des zones différentes de la cuve et ont conduit aux valeurs de l'échantillon (en unités) : $x_1 = 78$ ; $x_2 = 85$ ; $x_3 = 91$ ; $x_4 = 76$, réalisation des variables aléatoires $X_1$ ; $X_2$ ; $X_3$ ; $X_4$.
> L'entreprise a besoin d'estimer la viscosité et aussi de connaître la précision de cette estimation. Ayant choisi a priori un seuil de 5%, il s'agît de fournir aux clients des intervalles de confiance à 95% pour $\mu$.
> Le modèle considère que les variables $X_i$ sont indépendantes selon une loi $\mathcal N (\mu, \sigma)$, $\mu$ représente la moyenne de la viscosité de la cuve tandis que $\sigma$ prend en compte la variabilité de la viscosité au sein de la cuve et celle due à l'erreur de mesure.
> Les estimateurs des paramètres la moyenne $\mu$ et la variance $\sigma^2$ sont respectivement $$\footnotesize \overline X = {1 \over n} \sum_{i = 1}^n X_i \text{ et } S^2 = {1 \over {n - 1}} \sum_ {i = 1} ^n \left ( X_i - \overline X \right ) ^2 \text{ (ici, }n = 4\text{)}$$
> ### Préciser une estimation ponctuelle de $\mu$, puis une estimation ponctuelle de $\sigma^2$.

$$\overline x = {{78 + 58 + 91 + 76} \over 4} = 82,5 \quad \text{(estimation ponctuelle de } \mu \text{)}$$

$$\footnotesize \begin{aligned} 
s^2 &= {{\sum_{i = 1} ^n (X_1 - \overline X)^2} \over {n - 1}} = {n \over {n - 1}} {{\sum (X_i - \overline X )^2} \over n} = {{\sum (X_i - \overline X )^2} \over {n - 1}} \\
&= {{(78 - 82,5)^2 + (85 - 82,5)^2 + (91 - 82,5)^2 + (76 - 82,5)^2} \over 3} = 47 \end{aligned} \\
\text{(estimation ponctuelle de } \sigma^2 \text{)} $$ $$s = \sqrt 47 \approx 6,86 \quad \text{(estimation ponctuelle de } \sigma \text{)}$$

> ### Intervalle de confiance de $\mu$ avec $\sigma$ connu
> Il est admis que la variabilité du processus de fabrication est constante et connue avec $\sigma = 5$. Dans ce cas, l'estimateur de $\mu$, $\overline X$, est gaussien : $\overline X \sim \mathcal N \left ( \mu, {\sigma \over \sqrt n} \right )$.

> #### Donner un intervalle de confiance pour $\mu$ de niveau de confiance 95%.
> > L'intervalle de confiance pour $\mu$ de niveau de confiance $1 - \alpha$ est défini par $$P \left ( \left | {{\overline X - \mu} \over {\sigma / \sqrt n}} \right | \leqslant u_{1 - \alpha / 2} \right ) = 1 - \alpha$$
> Soit $$P \left ( \overline X - u_{1 - \alpha / 2 } {\sigma \over \sqrt n} \leqslant \mu \leqslant \overline X + u_{1 - \alpha/2} {\sigma \over \sqrt n} \right )  = 1 - \alpha $$

$$\begin{aligned}
\overline X &= {{X_1 + X_2 + X_3 + X_4} \over n} \sim \mathcal N \left ( \mu , {\sigma \over \sqrt n} \right ) = \mathcal N \left ( \mu, {5 \over 2} \right ) \\
&\Rightarrow T = {{\overline X - \mu} \over {\sigma / \sqrt n}} = {{\overline X - \mu} \over 2,5} \sim \mathcal N (0,1) \\
&\Rightarrow P \left ( \left \lvert {{ \overline X - \mu} \over {\sigma / \sqrt n}} \right \rvert \leqslant u_{0,975} \right ) = 0,95
\end{aligned}$$

L'intervalle de confiance est défini par  $\left \lvert {{ \overline X - \mu} \over {\sigma / \sqrt n}} \right \rvert \leqslant u_{0,975}$.

> #### Est-il à l'intérieur de la spécification $[75,85]$ ?

$$ \begin{aligned}
\left \lvert {{ \overline X - \mu} \over {\sigma / \sqrt n}} \right \rvert \leqslant u_{0,975} &\iff -u_{0,975} \leqslant {{\overline X - \mu} \over {\sigma / \sqrt n}} \leqslant u_{0,975} \\
&\iff - u_{0,975} \leqslant {{\mu - \overline X } \over {\sigma / \sqrt n}} \leqslant u_{0,975} \footnotesize \quad \text{(centré en 0)} \\
&\iff - u_{0,975} {\sigma  \over \sqrt n} \leqslant \mu - \overline X \leqslant u_{0,975} {\sigma  \over \sqrt n} \\
&\iff \overline X - u_{0,975} {\sigma  \over \sqrt n} \leqslant \mu  \leqslant \overline X + u_{0,975} {\sigma  \over \sqrt n} 
\end{aligned}$$ $$ \begin{aligned} 
IC_{0,95} = &\left [  \overline X + u_{0,975} {\sigma  \over \sqrt n} ;  \overline X - u_{0,975} {\sigma  \over \sqrt n} \right ] \\
\text{Réalisation : } &\left [ \overline x - u_{0,975} \times {\sigma \over \sqrt n} ; \overline x + u_{0,975} \times {\sigma \over \sqrt n} \right ] \\
\text{A.N. : } &\sigma = 5, \ \sqrt n = \sqrt 4, \ u_{0,975} = 1,96, \ \overline x = 82,5 \\
IC_{0,95} = &\left [ 82,5 - 1,96 \times {5 \over 2} ; 82,5 + 1,95 \times {5 \over 2 } \right ] \\
= & \ [ 77,6 \ ; 87,4 ] \subset [75, 95]
\end{aligned} $$

> ### Intervalle de confiance de $\mu$ avec $\sigma$ inconnu
> La variance n'est plus supposée constante et connue, elle doit être estimée. On utilise l'estimation $s^2$ trouvée ci-dessus.
> À présent, ${{\overline X - \mu} \over {S / \sqrt n}} \sim \mathcal T_{n - 1}$, loi de Student à $n - 1 = 3$ degrés de liberté.

> #### Donner un intervalle de confiance pour $\mu$ de niveau de confiance 95%.
> > $$P \left ( \left | {{\overline X - \mu} \over {S / \sqrt n}} \right |  \leqslant t_{n - 1 ; 1 - \alpha / 2} \right ) = 1 - \alpha $$ 

$$ \left |  {{ \overline X - \mu} \over {S / \sqrt n}} \right |  \leqslant t_{{n -1} \atop {1 - \alpha / 2}} \iff \overline X - t_{{n -1} \atop {1 - \alpha / 2}} {S \over \sqrt n} \leqslant \mu \leqslant \overline X + t_{{n -1} \atop {1 - \alpha / 2}}  \times {S \over \sqrt n} $$ $$\begin{aligned}
IC'_{0,95} = &\left [ \overline X - t_{3; 0,975} {S \over \sqrt n} ; \overline X + t_{3;0,975} {S \over \sqrt n} \right ] \\
\text{Réalisation : } &\left [ \overline x - t_{3;0,975} {s \over \sqrt n} ; \overline x + t_{3;0,975} {s \over \sqrt n} \right ] \\
\text{A.N. : } & \footnotesize \overline x = 82,5, \ t_{3;0,975} = 3,182, \ s = \sqrt 47 \approx 6,86, \ n = 4 \\
IC'_{0,95}  = &\footnotesize  \left [ 82,5 - 3,182 \times {6,82 \over 2} ; 82,5 + 3,182 \times {6,82 \over 2} \right ] \\ = &\ [71,6 \ ; \  93,4] \not\subset  [75,95]
\end{aligned}$$

> ### Intervalle de confiance de $\sigma$ avec $\mu$ inconnue
> La moyenne $\mu$ n'étant pas connue, $$(n - 1) {S^2 \over \sigma^2} \sim \chi_{n-1}^2 $$

> #### Donner un intervalle de confiance pour $\sigma$ de niveau de confiance 95%.
> > $$ P \left ( \chi_{n - 1; \alpha/2} \leqslant (n - 1) {S^2 \over \sigma^2} \leqslant \chi_{n - 1; 1 - \alpha/2} \right ) = 1 - \alpha $$

![](https://i.imgur.com/vLAnqiZ.png)
